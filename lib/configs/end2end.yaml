
# system setting
models_name: end2end


# logger options
image_save_iter: 10         # How often do you want to save output images during training
image_display_iter: 10       # How often do you want to display output images during training
display_size: 1               # How many images do you want to display each time
snapshot_save_iter: 5000     # How often do you want to save trained models
log_iter: 10                   # How often do you want to log the training stats

# optimization options
max_iter: 1000000             # maximum number of training iterations
batch_size: 4                # batch size train
weight_decay: 0.0001          # weight decay
beta1: 0.5                    # Adam parameter
beta2: 0.999                  # Adam parameter
init: kaiming                 # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.00005                   # initial learning rate always0.0001
lr_policy: step               # learning rate scheduler
step_size: 50000             # how often to decay learning rate
gamma: 0.5                    # how much to decay learning rate


relight: 10                  # weight of relight
gan_w: 0.1                      # weight of adversarial loss
vgg_w: 0                      # weight of domain-invariant perceptual loss
removal: 5
depth: 5
light: 5
shadow: 5



num_workers: 8                              # number of data loading threads
new_size: 512                               # first resize the shortest image side to this size
crop_image_height: 512                      # random crop image of this height
crop_image_width: 512                       # random crop image of this width
data_root: D:/Dataset/Relighting/hdr/     # dataset folder location
shadow_root: /media/guoxian/D/Dataset/3Dhuman/shadow/     # dataset folder location
light_root: D:/Dataset/Relighting/hdr/
vgg_model_path: data

scene_num: 9  # dataset folder location
subject_index_num: 7   # dataset folder location
shadow_plus_num: 6
shadow_plus_subject_index_num: 7
shadow_plus_scene_num: 9
k: 8                  # dataset folder location
nThreads:  8
n_ep: 3
resume: None
split_files_path: data/split_files.pick
cuda_device: 0
live: 0


